# paper-interesting
## ACL
### 1.Dialogue
| Num           | Paper                                                        | Time      | Summary                                                      |
| ------------- | ------------------------------------------------------------ | --------- | ------------------------------------------------------------ |
| 1             | [Prompter: Zero-shot Adaptive Prefixes for Dialogue State Tracking Domain Adaptation](https://aclanthology.org/2023.acl-long.252/)<br />Prompter: 用于DST领域自适应的零样本自适应前缀 | 2023 july | 对于DST对话状态跟踪，不使用监督数据让模型能够适应于新领域的挑战。文章提出使用目标领域的描述提示词生成动态前缀然后拼接到key和value上在每层的自注意力机制上。Prompter在多领域MultiWOZ和SGD基准测试中都优于以前的方法。**【DST】** |
| 3<br />day1   | [Span-Selective Linear Attention Transformers for Effective and Robust Schema-Guided Dialogue State Tracking](https://arxiv.org/abs/2306.09340) arxiv<br />用于高效和鲁棒的SGDST任务的SPLAT | 2023 june | 介绍了一种新型的对话状态跟踪模型，名为SPLAT，用于处理schema-guided对话状态跟踪任务。它通过将输出限制在有限的预测空间内，实现了更好的泛化和效率。同时，该模型允许在描述和历史之间进行丰富的注意力，此外通过引入线性时间注意力来控制计算成本。在SGD数据集上取得了85.3的JGA。**【DST】** |
| 36            | [Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking](https://aclanthology.org/2023.acl-long.114/)<br />划分、征服和合并：零样本DST的语义独立专家混合 | 2023 july | 为了能在零研究迁移学习即在没有领域内数据的情况下提高DST的性能。提出将已见数据分成语义独立的子集，并训练相应的专家，然后使用专家混合机制来处理新出现的数据，以提高性能和稳健性。该方法在MultiWOZ2.1数据集上达到SOTA，并只有10M训练参数【Zero-Shot  DST】 |
| 39* day7      | [BREAK: Breaking the Dialogue State Tracking Barrier with Beam Search and Re-ranking](https://aclanthology.org/2023.acl-long.159/)用bean搜索和重排打破DST障碍 | 2023 july | 引入了一个新的框架BREAK，它执行DST分为两个阶段:(i)用束搜索生成k-最佳对话状态候选;(ii)重新排序候选以选择正确的对话状态。这个简单框架在所有版本的MultiWOZ和M2M数据集上达到SOTA。此外在MultiWOZ 2.1-2.4上将JGA提高到80-90%，分别比以前性能最好的模型提高了23.6%、26.3%、21.7%和10.8%。【DST】[code](https://github.com/tony-won/DST-BREAK) |
| 8<br />day2   | [Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues](https://aclanthology.org/2023.acl-long.116/)<br />任务导向对话的模式引导用户满意度建模 | 2023 july | 提出了一种新的模式引导用户满意度建模框架SG-USM，明确建模用户对任务属性的满足程度，以预测用户满意度水平。SG-USM使用预训练语言模型编码对话和任务属性，接着实现表示层来学习对话中完成了多少任务属性，这是一个用于计算任务属性重要性的重要性预测组件，最后基于任务属性实现度和任务属性重要性预测用户满意度。实验结果显示SG-USM在多个基准数据集上表现更好。框架提高了用户满意度建模的可解释性，具有良好的可扩展性。[Code](https://github.com/amzn/user-satisfaction-modeling)<br />**【Task-Oriented Dialogues】** |
| 15* day3      | [DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue](https://aclanthology.org/2023.acl-long.199/)<br />DAMP: 针对任务型对话的双重多语言解析器 | 2023 july | 提出了DAMP，在Spanglish、Hinglish 和多语言任务解析基准上分别将mBERT的转移性能提高3、6和81倍，同时在参数比XLM-R 和 mT5-Large少3.2倍下胜出。<br />**【Task-Oriented Dialogue】** |
| 23            | [One Cannot Stand for Everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems](https://aclanthology.org/2023.acl-long.1/)<br />一个人不能代表所有人!利用多用户模拟器来训练面向任务的对话系统 | 2023 july | 提出MUST框架通过充分利用多用户模拟器来优化ToD系统。将MUST构建为一个Multi-armed bandits问题，并提供了一种称为MUST adaptive的方法，以平衡i）不同用户模拟器和ToD系统之间的自适应交互的增强适应性，和ii）避免灾难性遗忘问题的统一适应性。在MultiWOZ上通过MUST训练的对话系统在性能上优于单一用户模拟器训练的系统。<br />【Task-oriented Dialogue】 |
| 42            | [FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for Task-Oriented Dialogue](https://arxiv.org/abs/2306.10315) arxiv<br />将未来知识传授给任务导向对话的预训练语言模型 | 2023 july | 提出了一种新颖的对话预训练模型FutureTOD，它使用自训练框架将未来的知识提取到先前对话上下文的表示中。作者认为良好的对话表示应该能够同时学习本地上下文信息并预测未来信息。在各种下游对话任务上的大量实验证明了模型的有效性。【Task-Oriented Dialogue】 |
| 20<br />day4  | [White-Box Multi-Objective Adversarial Attack on Dialogue Generation](https://aclanthology.org/2023.acl-long.100/)<br />对话生成上的白盒多目标对抗攻击 | 2023 july | 提出了一种名为DGSlow的白盒多目标攻击方法。DGSlow通过基于梯度的多目标优化器平衡了两个目标——生成准确性和长度，通过自适应搜索机制迭代地制作仅经过少量修改的对抗性样本。【Dialogue Generation】 |
| 24            | [PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism](https://aclanthology.org/2023.acl-long.185/)<br />通过伪变分机制生成多样而相关的对话响应 | 2023 july | 提出Pseudo-Variational Gated Recurrent Unit (PVGRU)。它的关键创新是一种循环汇总变量，它汇总子序列的累积分布变化。在训练PVGRU时不依赖后验知识，从而避免了训练-推理不一致的问题。VGRU可以通过汇总变量来感知细微的语义变化。<br />【Dialogue Response Generation】 |
| 27*           | [Envisioning Future from the Past: Hierarchical Duality Learning for Multi-Turn Dialogue Generation](https://aclanthology.org/2023.acl-long.407/)<br />从过去展望未来：用于多轮对话生成的层次二元学习 | 2023 july | 提出了一种用于对话的层次二元学习（HDLD），来模拟人类在对话中推断未来文本的能力。通过最大化过去和未来话语之间的相互信息，生成既连贯又信息丰富的回应。以前的方法仅在训练期间将未来文本作为辅助信息进行编码，HDLD允许对话历史和未来之间的互动，提高对话数据的利用。【 Dialogue Generation】 |
| 33            | [Enhancing Dialogue Generation via Dynamic Graph Knowledge Aggregation](https://aclanthology.org/2023.acl-long.253/)<br />通过动态图知识聚合增强对话生成 | 2023 july | 现有模型的训练机制导致了图知识和文本之间的语义差距。通过动态构造了一个带有伪节点的多跳知识图，使语言模型在图内的每一步都参与特征聚合，该框架可以更好地利用来自文本和外部图知识的异构特征。<br />【Dialogue Generation】[code]( https://github.com/tangg555/SaBART) |
| 34            | [Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona](https://aclanthology.org/2023.acl-long.299/)<br />对比潜在变量增强个性化对话生成:结合稀疏和密集角色 | 2023 july | 设计了一个基于对比潜在变量的模型(CLV)，该模型将密集的人物角色描述聚类到稀疏的类别中，并将其与历史查询相结合以生成个性化的响应。在中文和英文数据集上的实验结果表明了模型在个性化方面的优越性。<br />【Personalized Dialogue Generation】 |
| 46 day8       | [Contextual Knowledge Learning for Dialogue Generation](https://arxiv.org/abs/2305.18200) arxiv<br />对话生成的上下文知识学习 | 2023 july | 提出了一种将对话背景和知识加权作为模型训练的一个重要部分。通过一种称为上下文知识学习（CKL）过程来引导模型训练，该过程包括上下文和知识的潜在向量。CKL潜在向量通过弱监督捕捉了对话背景、知识和响应之间的关系，使在训练过程中能够差异化地权衡对话背景话语和知识句子。【Dialogue Generation】 |
| 47            | [SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation](https://arxiv.org/abs/2305.11130)<br />通过过度抽样和事后评估提高基于人物的对话生成的连贯性和一致性 | 2023 july | 对于基于人物的对话生成任务，一致性和连贯性是关键因素，提出了一种简单而有效的两阶段SimOAP策略，即过采样和后评价。过采样阶段通过现成的蒸馏和压缩方法有效地从现有训练模型中获得大规模响应。后评价阶段根据多个精心设计的评价指标从大规模候选对象中选择一个好的响应。【Dialogue Generation】 |
### 2.Conversation
| Num           | Paper                                                        | Time      | Summary                                                      |
| ------------- | ------------------------------------------------------------ | --------- | ------------------------------------------------------------ |
| 1              | [MPCHAT: Towards Multimodal Persona-Grounded Conversation](https://aclanthology.org/2023.acl-long.189/)<br />面向多模态基于角色的对话 | 2023 july | 将基于人物的对话扩展到多模态领域并做出了两个主要贡献。第一是提出了第一个名为MPCHAT的多模态基于人物角色的对话数据集，将人物角色扩展为文本和图像以包含情景记忆。第二结合多模态角色，通过三个提出的基于多模态角色的对话任务来衡量，在统计上显著提高了所有任务效果。【Multi modal conversation】 |
| 11 day10       | [MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations](https://aclanthology.org/2023.acl-long.824/)<br />面向对话情感识别的基于注意力关联感知的多模态融合框架 | 2023 july | 提出了名为MultiEMO的新型基于注意力和关联感知的多模态融合框架，通过双向多头跨模态注意力层捕获文本、音频和视觉模态之间的跨模态映射关系，有效地整合多模态线索。还提出了Sample-Weighted Focal Contrastive (SWFC) 损失来减轻识别少数和语义上难以区分的情感类别的困难。【Emotion Recognition】 |
| 17             | [A Cross-Modality Context Fusion and Semantic Refinement Network for Emotion Recognition in Conversation](https://aclanthology.org/2023.acl-long.732/)<br />用于对话情感识别的跨模态上下文融合和语义精炼网络 | 2023 july | 以往的研究大多是简单地将多模态表征连接起来，导致冗余信息的积累和模态之间的上下文交互作用有限。因此提出CMCF-SRNet，先设计了一个跨模态位置约束transformer来探索多模态相互作用。再研究了一种基于图的语义精炼transformer，解决了话语间语义关系信息不足的局限性。[code]( https://github.com/zxiaohen/CMCF-SRNet)【Emotion Recognition】 |
| 19*            | [A Facial Expression-Aware Multimodal Multi-task Learning Framework for Emotion Recognition in Multi-party Conversations](https://aclanthology.org/2023.acl-long.861/)<br />在多方对话中面部表情感知的多模态多任务学习框架 | 2023 july | 以往的MERMC研究大多侧重于文本和音频模式，而忽略了视觉信息。给定一个话语，以前的方法提取的人脸序列可能包含多个人脸，提出了一个两阶段的框架，称为面部表情感知多模态多任务学习(FacialMMT)。先提取每个话语的真实说话人的面部序列，再多模态面部表情感知情感识别模型利用帧级面部情绪分布来帮助改进基于多任务学习的话语级情感识别。[code](https://github.com/NUSTM/FacialMMT)【Emotion Recognition/ Multi-party】 |
| 5              | [Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations](https://aclanthology.org/2023.acl-long.606/)<br />情感识别对话中的监督对抗对比学习 | 2023 july | 提出了一种监督对抗对比学习（SACL）框架，以有监督的方式学习类别分布结构化表示。设计了一种上下文对抗训练（CAT）策略，以从上下文中学习更多多样性特征。并开发了一种基于序列的SACL-LSTM，用于学习ERC的标签一致和上下文鲁棒特征。【Emotion Recognition】 |
| 7              | [TREA: Tree-Structure Reasoning Schema for Conversational Recommendation](https://aclanthology.org/2023.acl-long.167/)<br />基于树结构推理模式的会话推荐 | 2023 july | 会话推荐系统(CRS)旨在通过对话及时跟踪用户的动态兴趣，并生成相关的项目推荐。提出了一种新的树结构推理模式TREA。TREA构建了一个多层可扩展的树作为推理结构，阐明被提及实体之间的因果关系，并充分利用历史对话，对推荐结果产生更合理、更合适的响应。**【Conversational Recommendation】** |
### 3.Interaction
| Num           | Paper                                                        | Time      | Summary                                                      |
| ------------- | ------------------------------------------------------------ | --------- | ------------------------------------------------------------ |
| 5        | [Causality-Guided Multi-Memory Interaction Network for Multivariate Stock Price Movement Prediction](https://aclanthology.org/2023.acl-long.679/)<br />多元股价走势预测的因果导向多记忆交互网络 | 2023 july | 在预测某只股票时，作者假设来自其他股票的信息也应该被用作辅助数据来提高业绩。提出了一种新的端到端深度神经网络——因果关系引导的多记忆交互网络(CMIN)，该网络首次将金融文本数据与因果关系增强的股票相关性之间的多模态建模，以达到更高的预测精度。【Stock Price Prediction】 |
| 9        | [LayoutMask: Enhance Text-Layout Interaction in Multi-modal Pre-training for Document Understanding](https://aclanthology.org/2023.acl-long.847/)<br />增强文本布局交互在多模态预训练中为了文档理解 | 2023 july | 可视化富文档理解，主要的挑战是如何将文档的不同模式(文本、布局和图像)融合到具有不同预训练任务的统一模型中。提出了一种新的多模态预训练模型LayoutMask，增强统一模型中文本和布局模态之间的交互，并为下游任务产生自适应和鲁棒的多模态表示。==【Document Understanding】== |

## AAAI
### 1.Dialogue

| Num  | Paper                                                        | Summary                                                      |
| :--: | ------------------------------------------------------------ | ------------------------------------------------------------ |
|  14  | [Dialogue State Distillation Network with Inter-slot Contrastive Learning for Dialogue State Tracking](https://ojs.aaai.org/index.php/AAAI/article/view/26620)<br />DST上的基于槽间对比学习的对话状态蒸馏网络 | 不同slots的更新之间的关系为DST提供了重要的线索，现有的方法仅依赖于预定义的图来间接捕获关系。作者提出了一种对话状态蒸馏网络(DSDN)来利用以前对话状态的相关信息，弥补训练和测试之间的利用差距。还提出了一个槽间对比学习损失，以有效地捕获对话上下文中的槽共同更新关系。在MultiWOZ 2.0/2.1达到SOTA。【DST】 |
|  10  | [Towards Complex Scenarios: Building End-to-End Task-Oriented Dialogue System across Multiple Knowledge Bases](https://ojs.aaai.org/index.php/AAAI/article/view/26581)<br />面向复杂场景:跨多个知识库构建端到端的面向任务的对话系统 | 大多数现有的etod仅限于单个KB设置，作者考虑了etod中的多kb场景，并引入了KB-over-KB异构图注意网络(kk - han)来促进模型对多个kb的推理。核心模块是一个三重连接图交互层，可以跨不同kb(即kb内连接、kb间连接和对话- kb连接)对不同粒度级别的交互信息进行建模。实验结果证实了该模型在多KBs推理中的优越性。【Task-Oriented Dialogue】 |
|  15  | [Balanced Meta Learning and Diverse Sampling for Lifelong Task-Oriented Dialogue Systems](https://ojs.aaai.org/index.php/AAAI/article/view/26621)<br />终身任务导向对话系统的平衡元学习和多样化采样 | 作者提出了一种两阶段终身任务导向的对话生成方法，以减轻灾难性遗忘并同时鼓励知识转移。设计了一种平衡的元学习策略，用于终身学习过程中的前向和后向知识转移。采用基于不确定性的采样策略，选择并存储有代表性的对话样本到情景记忆中以进行向后知识迁移。[code](https: //github.com/travis-xu/MetaLTDS.)【 lifelong Task-Oriented Dialogue 】 |
|  12  | [Taming Continuous Posteriors for Latent Variational Dialogue Policies](https://ojs.aaai.org/index.php/AAAI/article/view/26602)<br />潜在变分对话策略的连续后验驯服 | 绝对后验一直被认为是表现的主要驱动因素之一。作者重新审视了潜在动作强化学习的高斯变分后验，并表明它们可以产生比分类更好的性能。使用连续潜表示，我们的模型在MultiWOZ基准上实现了最先进的对话成功率。【Task-oriented Dialogue】 |

### 2.Conversation
| Num  | Paper                                                        | Summary                                                      |
| :--: | ------------------------------------------------------------ | ------------------------------------------------------------ |
|  2   | [CP-Rec: Contextual Prompting for Conversational Recommender Systems](https://ojs.aaai.org/index.php/AAAI/article/view/26487)<br />对话推荐系统的上下文提示 | 作者提出了一个新的对话管理上下文提示框架，它基于上下文、主题和用户配置文件优化提示。并进一步采用外部知识来丰富用户档案，并提供基于知识的推荐。结合这些技术，提出了一个具有上下文提示的会话推荐系统CP-Rec。【Recommender Systems】 |
|  6   | [BERT-ERC: Fine-Tuning BERT Is Enough for Emotion Recognition in Conversation](https://ojs.aaai.org/index.php/AAAI/article/view/26582)<br />微调BERT是足够的对于对话情感识别 | 作者提出了一种新的范式，即在微调步骤中探索上下文信息和对话结构信息，并在输入文本、分类结构和训练策略方面使PLM适应ERC任务。根据提此范式开发了BERT-ERC模型，从暗示性文本、细粒度分类模块和两阶段训练三个方面提高ERC性能。大量实验表明，所提出的范式明显优于先前的范式，并且可以适应各种场景。【Emotion Recognition】 |


