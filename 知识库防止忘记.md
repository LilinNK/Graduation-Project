## 李's 知识库

### 0. 常用链接

  🤖[NLP大作业参考](https://github.com/yangxze/ChatGLM-LangChain)
  😻[台大李弘毅老师的课程主页](https://speech.ee.ntu.edu.tw/~hylee/index.php)
  ⚛[openAI](https://openai.com/)
  🤗[Hugging Face](https://huggingface.co/)
  🖌️[做图软件](https://www.canva.cn/)


### 1. Hugging Face（transformers🤗）

#### 1.1 相关写的不错的入门笔记：

1.1.1 [指导笔记上篇](https://zhuanlan.zhihu.com/p/448852278)  
  - 主要内容
    
    **安装**
    ```pyhton
    #直接使用如下命令安装会好一些，多安装依赖库：sentencepiece 和 protobuf
    !pip install transformers[sentencepiece]
    ```
    **pipeline背后的流程(值得弄懂！)**
    <img width="1774" alt="image" src="https://github.com/LilinNK/Graduation-Project/assets/96948927/9906abb2-de06-4533-be96-0937d8459a6c">

    <img width="1767" alt="image" src="https://github.com/LilinNK/Graduation-Project/assets/96948927/48e47e1e-2e54-4a2b-9ec5-31306591ccb8">

    **Tokenizer:** [AutoTokenizer](https://huggingface.co/docs/transformers/v4.39.3/en/model_doc/auto#transformers.AutoTokenizer)
    ```
    from transformers import AutoTokenizer

    # Download vocabulary from huggingface.co and cache.
    tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
    
    # Download vocabulary from huggingface.co (user-uploaded) and cache.
    tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")
    
    # If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
    # tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")
    
    # Download vocabulary from huggingface.co and define model-specific arguments
    tokenizer = AutoTokenizer.from_pretrained("FacebookAI/roberta-base", add_prefix_space=True) #add_prefix_space 指在编码文本时是否在词之前添加一个空格
    ```
    **Models**
    ```
    from transformers import AutoConfig, AutoModel
    
    # Download model and configuration from huggingface.co and cache.
    model = AutoModel.from_pretrained("google-bert/bert-base-cased")
    
    # Update configuration during loading
    model = AutoModel.from_pretrained("google-bert/bert-base-cased", output_attentions=True)  #给定输入，会有注意力权重可以输出
    model.config.output_attentions
    
    # Loading from a TF checkpoint file instead of a PyTorch model (slower)
    config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
    model = AutoModel.from_pretrained(
        "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
    )
    ```
    **对应的预训练文档为：**
    
    config:模型架构文件。

    pytorch_model.bin(tf_model.h5,flax_model.msgpack,model.safetensors):模型具体参数文件。

    vocab(merges,special_tokens_map,tokenizer,tokenizer_config):分词预处理的文件。

    eg:
    Bert: vocab.txt => Roberta: merge.txt+vocab.json 分词编码不同  Bert：BPE编码，Roberta：byte level的BPE(BBPE)[参看](https://blog.csdn.net/ljp1919/article/details/113616226)


1.1.2 常用安装命令

    ```
    pip install transformers[sentencepiece]
    
    pip install datasets
    
    pip install evaluate
    
    pip install pandas
    
    pip install torch
    
    pip install peft
    
    pip install scikit-learn
    
    **pip install -help**  #可以查看各种pip参数
    
    pip install -r requirement.txt
    
    pip install -u scikit-learn  #升级到最新版本
    
    pip install -q transformers  #安静安装，不输出安装信息，只输出成功/失败

    pip list   #运行这个命令，它会列出当前Python环境中安装的所有包及其版本号
    
    pip show package_name   #查看特定包的版本
    
    ```
#### 1.2 常用函数导入

    ```
    from sklearn.metrics import f1_score, accuracy_score, classification_report

    from transformers import RobertaModel, BertModel, RobertaConfig,DebertaModel,DebertaConfig,DebertaV2Model,DebertaV2Config

    
    ```

### 2. Linux

#### 2.1 常用命令行（[参考](https://www.autodl.com/docs/linux/)）

  ```
  #查看目录
  ls  #列出当前目录下的文件和文件夹
  ls -l  #列出文件和文件夹的详细信息：权限，Owner，Group和创建/更新时间
  ls -a  #列出所有文件，包括.开头的隐藏文件

  #重命名、创建、移动文件/文件夹
  touch newfile.txt    #创建文件
  mkdir test_dir #创建新路径
  mv test_dir/ test_directory #重命名
  mv a b/  #把a移动到b目录下，如果b目录不存在则变为重命名
  cp -r a b   #将a文件夹拷贝到b文件夹下，-r代表递归拷贝
  rm -rf folder  #删除文件/文件夹
  rm -rf folder/*   # *是通配符号，这样代表folder文件夹下所有文件/文件夹

  #查看路径
  cd   #切换路径
  pwd  #查看工作路径
  .. or ../  #上一级目录
  . or ./  #同级目录

  #查看gpu
  nvidia-smi #查看此时情况
  nvidia-smi -l 1 / watch -n 1 nvidia-smi #每隔1秒输出一次

  #查看进程
  ps -ef
  #-e 选项表示显示所有进程，而不仅仅是由当前用户拥有的进程。
  #-f 选项表示显示完整格式，这通常包括进程 ID (PID)、父进程 ID (PPID)、用户 ID (UID)、启动时间、控制终端、CPU 使用时间以及命令名称等信息。

  #杀死进程
  kill -9 402  #402是进程ID PID
  ```

